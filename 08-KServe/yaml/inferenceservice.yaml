apiVersion: serving.kserve.io/v1beta1
kind: InferenceService
metadata:
  name: covid-19                          # KFServing InferenceService 명
spec:
  predictor:
    serviceAccountName: kserve-sa         # s3:// 레파지토리(Minio)를 사용하기 위해 이 Kserve InferenceService가 사용할 serviceAccount (Step1.에서 생성함)
    tensorflow:
      storageUri: 's3://{project-namespace}/covid-19/'  # 모델을 저장한 경로 s3://<bucket명>/<저장경로>
      resources:
        limits:
          cpu: '1'
          memory: 2Gi
        requests:
          cpu: 500m
          memory: 1Gi