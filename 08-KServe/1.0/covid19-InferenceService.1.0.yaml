apiVersion: serving.kubeflow.org/v1alpha2
kind: InferenceService
metadata:
  name: covid-19        # KFServing InferenceService 명
  namespace: myspace   # KFServing InferenceService가 배포될 Namespace
spec:
  default:
    predictor:
      serviceAccountName: kfserving-sa   # s3:// 레파지토리(Minio)를 사용하기 위해 이 KFServing InferenceService가 사용할 serviceAccount (Step1.에서 생성함)
      tensorflow:
        storageUri: 's3://saved-model/covid-19/'  # 모델을 저장한 경로 s3://<bucket명>/<저장경로>
        resources:
          limits:
            cpu: 100m
            memory: 1Gi
          requests:
            cpu: 100m
            memory: 100Mi
